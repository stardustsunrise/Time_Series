---
title: "Time Series Project"
author: "Group 1"
date: "2026-01-31"
output: pdf_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## R Markdown

This is an R Markdown document. Markdown is a simple formatting syntax for authoring HTML, PDF, and MS Word documents. For more details on using R Markdown see <http://rmarkdown.rstudio.com>.

When you click the **Knit** button a document will be generated that includes both content as well as the output of any embedded R code chunks within the document. You can embed an R code chunk like this:

```{r}

```
#Import datasets
```{r}
library(readr)
library(ggplot2)
library(quantmod) # loading data sets from online
library(dplyr) # for the pipes
library(kableExtra) # for kable
library(lubridate) # for years...
library(knitr)
library(tidyr)

#Downloading data from (github/statscan) for processing
#Data= Prices of various food products, by Province in Canada, from January 2002 to November 2025. Prices are measured in CAD per Metric Tonne
Data_Price <- read.csv("https://raw.githubusercontent.com/stardustsunrise/Time_Series/refs/heads/main/3210007701_databaseLoadingData.csv")

head(Data_Price)
str(Data_Price)

print(Data_Price)


#Convert to data frame


Price_data = data.frame(Date= as.Date(paste0(Data_Price$REF_DATE,"-01")), 
                        Price_per_MTonne= Data_Price$VALUE,
                        
                        Product=c("Wheat (except durum wheat) [1121111]"))
print(Price_data)


Price_chart = ggplot(Price_data, aes(x=Date,y= Price_per_MTonne, group=1))+
                       geom_line(color="green", size=1)+
                       labs(
                         title = "Price of Farm products per Month",
                         subtitle= "2002-2025",
                         x="Date (Monthly)",
                         y="Price (Monthly)",
                         Caption= " Source Stats can"
                       )
print(Price_chart)

# Averaging the price of "Wheat (except durum wheat) [1121111]" accross all provinces to have 1 avg monthly price value for whole of Canada
Price_data<-Price_data%>%
  group_by(Date)%>%
  summarise(avg_price_canada=mean(Price_per_MTonne,na.rm= TRUE))%>%
  ungroup()


print(Price_data)

Price_chart2 = ggplot(Price_data, aes(x=Date,y=avg_price_canada, group=1))+
  
  geom_line(color="black", size =1)+
  labs(
    title="Price of Wheat, Excluding Durum",
    subtitle = "2002-2025",
    x="Date(Monthly)",
    y="Average of Price Accross Canada per",
    caption="Source: Statistics Canada. Table 32-10-0351-01 Prices of Farm products----double check"
  )
print(Price_chart2)


#Descriptive Statistics
summary(Price_data)

desc_stat1<- Price_data%>%
  summarise(
    Observation=n(),
    Starting_Date=min(Date),
    End_Date=max(Date),
    Mean=mean(Price_data$avg_price_canada),
    SD=sd(Price_data$avg_price_canada)
  )
print(desc_stat1)

desc_stat2<-Price_data%>%
  summarise(
    Min=min(avg_price_canada),
    Q1 = quantile(avg_price_canada, 0.25),
    Median = median(avg_price_canada),
    Q3 = quantile(avg_price_canada, 0.75),
    Max = max(avg_price_canada),
#Missing_Values = missing_count
)
print(desc_stat2)

kable(desc_stat1,
      caption = "Descriptive Statistics: Price Per Tonne Wheat(excluding Durum)",
      col.names = c("Observation", "Start Date", "End Date", "Mean", "Std Dev"), digits=2)%>%
  kable_styling(latex_options = c("striped","hold_position", "scale_down"))



kable(desc_stat2,
      caption="Descriptive Statistics: Price Per Tonne Wheat(excluding Durum)",
      col.names= c("Minimum","Q1","Median","Q3","Maximum"),
      digits=2)%>%
      kable_styling (latex_options = c("striped", "hold_position", "scale_down", position = "center"))



```


```{r}


library(patchwork)
library(tseries)
library(gridExtra)
         
print(Price_data)
#2.1 Removing Trend

#converting time series to object

Price_data_ts=ts(Price_data$avg_price_canada,
                 start = c(2002-01-01,1),
                 frequency = 12)

str(Price_data_ts)

#calculate transformation
Diff=diff(Price_data_ts)#First difference
Log_diff=diff(log(Price_data_ts))#Difference of Logarithms

#create dataframe for visualisation
Price_data_transform=data.frame(
  Date=Price_data$Date[-1],
  Diff=as.numeric(Diff),
  Log_diff=as.numeric(Log_diff)
)

p1=ggplot(Price_data_transform,aes(x=Date,y=Diff))+
  geom_line(color="blue")+
  labs(title = "Wheat Price Data Set- First Difference",
       x="Date",
       y="Price per Ton")

p2=ggplot(Price_data_transform,aes(x=Date,y=Log_diff))+
  geom_line(color="green")+
  labs(title = "Wheat Price Data Set- Log Difference",
       x="Date",
       y="Price per Ton")

#display side by side
p1/p2
# preference for log difference



#2.2 Removing seasonal component

library(forecast)

#Indentifying Seasonality

par(mfrow=c(1,2))
Acf(Diff,
main = "ACF of diff(Price of Wheat)",
lag.max = 300,
xlab = "Months", 
xlim=c(1,300))

Acf(Log_diff,
    main = "ACF of diff(log(Price of Wheat))",
    lag.max = 300,
    xlab = "Months", 
    xlim = c(1, 300))

#Test for iid noise

# Ljung-Box tests
cat("1. Ljung-Box tests (H0: No autocorrelation up to lag 48):\n\n")
## 1. Ljung-Box tests (H0: No autocorrelation up to lag 48):

Box.test(Diff, lag = 12, type = "Ljung-Box")


Box.test(Diff, lag = 12, type = "Ljung-Box")


plot(Log_diff,type="l",xlab="n", ylab=expression("Log_diff"))
abline(h=0,col="darkgreen",lty=2)



# Removing Seasonality

P_D1<-diff(Log_diff,difference=1)
P_D3<-diff(Log_diff,differences=3)
P_D12<-diff(Log_diff,differences=12)
P_D24<-diff(Log_diff,differences=24)

# First order difference

plot( P_D1, type = 'l', xlab = 'Months' , ylab = expression(nabla*"Price Per Ton"))


#third order difference
plot( P_D3, type = 'l', xlab = 'Months', ylab = expression(nabla^3*"Price Per Ton"))

#12th order difference
plot( P_D12, type = 'l', xlab = 'Months', ylab = expression(nabla^12*"Price Per Ton"))

#24th order difference
plot( P_D24, type = 'l', xlab = 'Months', ylab = expression(nabla^24*"Price Per Ton"))


#preference to Difference of 1st order

Deseasonlised_pricedata=P_D1
#2.3 Analysis of differenced Series (Price Data)
library(ggplot2)
Mean_pricedata=mean(Deseasonlised_pricedata)

Mean_pricedata

Variance_pricedata=var(Deseasonlised_pricedata)

Variance_pricedata

Standard_dav_Pricedata=sqrt(Variance_pricedata)
Variance_pricedata

summary(Deseasonlised_pricedata)


lower = qnorm(mean = Mean_pricedata, sd = Standard_dav_Pricedata, p=0.05)

upper = qnorm(mean = Mean_pricedata, sd = Standard_dav_Pricedata, p=0.95)

plot(Deseasonlised_pricedata, type = 'l', main = 'Price Data, deseasonalized', xlab = 'month', ylab = "Wheat shipped, tonnes")
abline(h = 0, col = 'darkblue', lty = 2)
abline(h = lower, col = 'darkgreen', lty = 2)
abline(h = upper, col = 'darkred', lty = 2)


#Check if 95% is within.
number=0
for(n in 1:length(Deseasonlised_pricedata)){
  if(Deseasonlised_pricedata[n]>upper){
    number=number+1
  }
  if(Deseasonlised_pricedata[n]<lower){
    number=number+1
  }
}
 number
 
 #29 out of 287 (about 10%) of the values lie outside this range. If the process is stationary, about 5% (14.35) should lie outside this interval on average.
 
 acf(Deseasonlised_pricedata, 
    main="ACF of deseasonalized series",
    lag.max = 300,
    xlab = "Months",
    xlim=c(1,12)
  )

 
```

#Question 3: filtering
## 3.1 Linear Smoothing
We have $$X̃_t = (1/(2q+1)) Σ_{j=-q}^{q} X_{t-j}$$
```{r}
# Apply filtering to log-differenced series
Series_to_filter <- Price_data_ts
n <- length(Series_to_filter)

# --- q = 6 ---
q1 <- 6 #this is in the range from 5 to 9, helping reduce the high volatility of the data
weights1 <- rep(1/(2*q1+1), 2*q1+1)

Linear_filtered_q6 <- stats::filter(
  Series_to_filter,
  filter = weights1,
  sides = 2
)

# --- q = 12 ---
q2 <- 12 #this helps to address the seasonality of the data
weights2 <- rep(1/(2*q2+1), 2*q2+1)

Linear_filtered_q12 <- stats::filter(
  Series_to_filter,
  filter = weights2,
  sides = 2
)

# --- Plot ---
plot(Series_to_filter, type="l", col="black",
     main="Linear Moving Average Filter Price Data",
     ylab="Values")

lines(Linear_filtered_q6, col="blue", lwd=2)
lines(Linear_filtered_q12, col="red", lwd=2)

legend("topright",
       legend=c("Original", "q = 6", "q = 12"),
       col=c("black", "blue", "red"),
       lty=1, lwd=c(1,2,2))

```
Justification of q = 12:
Monthly data → annual seasonal structure ≈ 12 months.
Justification of q = 6:
The data shows a decently high level of volatility (or high variance in other terms).
##3.2 Exponential Smoothing Filter

$$X̃_t = α X_t + (1−α) X̃_{t−1}$$


```{r}
exponential_smoothing <- function(X, alpha) {
  N <- length(X)
  X_smooth <- rep(NA, N)
  
  # Initialize with first observation
  X_smooth[1] <- X[1]
  
  # Recursive smoothing
  for (t in 2:N) {
    X_smooth[t] <- alpha * X[t] + (1 - alpha) * X_smooth[t - 1]
  }
  
  return(X_smooth)
}

# --- Alpha for seasonal smoothing ---
X_exp1 <- ts(exponential_smoothing(Price_data_ts, alpha = 0.2),
             start = start(Price_data_ts),
             frequency = frequency(Price_data_ts))
# --- Alpha for high volatility ---
X_exp2 <- ts(exponential_smoothing(Price_data_ts, alpha = 0.8),
             start = start(Price_data_ts),
             frequency = frequency(Price_data_ts))
plot.ts(Price_data_ts,
        main = 'Exponential Smoothing Comparison Price Data',
        xlab = 'Time',
        ylab = 'Values')

lines(X_exp1, col = 'red')
lines(X_exp2, col = 'blue')

abline(h = 0, col = 'black', lty = 2)

legend("topright",
       legend = c("Original", "alpha = 0.2", "alpha = 0.8"),
       col = c('black', 'red', 'blue'),
       lty = 1,
       lwd = 2)
```

I would recommend the linear filter since the Exponential one does not appear to make as big of a difference. The optimal filtering from the ones chosen is linear with q=12 as it appears to be the most smooth from those seen


#Question 4 – Stationarity Analysis
# Chosen plot
```{r}
plot(Deseasonlised_pricedata, type = 'l', main = 'Price Data, deseasonalized', xlab = 'month', ylab = "Wheat shipped, tonnes")
abline(h = 0, col = 'darkblue', lty = 2)
abline(h = lower, col = 'darkgreen', lty = 2)
abline(h = upper, col = 'darkred', lty = 2)
```
The deseasonalized series was chosen since it does not appear to have a trend or a major seasonal component, whereas the filtered data appears to still have a trend. Now we can test for stationarity
##4.1 Testing Weak Stationarity
```{r}
Stationary_series <- Deseasonlised_pricedata
library(tseries)

# ADF Test
adf.test(Stationary_series)

# KPSS Test
kpss.test(Stationary_series)

```
H0: time series is stationary,
H1: H0 is false.
We get ADF p < 0.05 and KPSS p > 0.05, and thus weak stationarity is supported, we fail to reject the null hypothesis.

##4.2 Autocorrelation Function (ACF)
$$ρ^​(h)=∑t=1n​(Xt​−Xˉ)2∑t=h+1n​(Xt​−Xˉ)(Xt−h​−Xˉ)​$$
```{r}
ACF_estimator <- function(X, hmax){
  n <- length(X)
  X_bar <- mean(X)
  acf_vals <- numeric(hmax+1)
  
  for(h in 0:hmax){
    num <- sum((X[(h+1):n]-X_bar)*
                 (X[1:(n-h)]-X_bar))
    den <- sum((X-X_bar)^2)
    acf_vals[h+1] <- num/den
  }
  
  return(acf_vals)
}

hmax <- 40
acf_values <- ACF_estimator(Stationary_series, hmax)

# 95% CI
CI <- 1.96/sqrt(length(Stationary_series))

plot(0:hmax, acf_values, type="h",
     main="Estimated ACF",
     xlab="Lag", ylab="ACF")
abline(h=0)
abline(h=CI, col="red", lty=2)
abline(h=-CI, col="red", lty=2)

```
We have some seasonal spikes, which means there is remaining periodicity.
##4.3 Custom PACF Function
```{r}
PACF_estimator <- function(X, hmax){
  pacf_vals <- numeric(hmax)
  
  for(h in 1:hmax){
    model <- ar(X, order.max=h, aic=FALSE, method="yw")
    pacf_vals[h] <- model$ar[h]
  }
  
  return(pacf_vals)
}

pacf_values <- PACF_estimator(Stationary_series, hmax)

plot(1:hmax, pacf_values, type="h",
     main="Estimated PACF",
     xlab="Lag", ylab="PACF")
abline(h=0)
abline(h=CI, col="blue", lty=2)
abline(h=-CI, col="blue", lty=2)

```
Looks like there is gradual decay and thus this may be an MA process.
